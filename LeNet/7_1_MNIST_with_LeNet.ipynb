{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.1 MNIST with LeNet",
      "provenance": [],
      "collapsed_sections": [
        "fFdjKP0kuL39",
        "uAhXPgZuublL",
        "l8JAyLjWvLWH",
        "0supgTUEvNV5"
      ],
      "authorship_tag": "ABX9TyOO5t0G8jEm1YyPUqLkBWOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdzafri/openvino-workshop/blob/main/LeNet/7_1_MNIST_with_LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsQJFOieRtEu"
      },
      "source": [
        "# MNIST with LeNet\n",
        "Understanding and Implementing LeNet-5 CNN Architecture\n",
        "\n",
        "Reference:\n",
        "1.   [Richmond Alake](https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342)\n",
        "2.   [Jeff Heaton](https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_06_2_cnn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFdjKP0kuL39"
      },
      "source": [
        "# 1. Dataset Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1uXvOTePrF3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDYJf_n6oEH3"
      },
      "source": [
        "# Load the dataset\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhFjvzUsqzX1"
      },
      "source": [
        "# OPTIONAL: Display some dataset samples as an image \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "ROWS = 6\n",
        "random_indices = random.sample(range(x_train.shape[0]), ROWS*ROWS)\n",
        "sample_images = x_train[random_indices, :]\n",
        "plt.clf()\n",
        "\n",
        "fig, axes = plt.subplots(ROWS,ROWS, \n",
        "                         figsize=(ROWS,ROWS),\n",
        "                         sharex=True, sharey=True) \n",
        "\n",
        "for i in range(ROWS*ROWS):\n",
        "    subplot_row = i//ROWS \n",
        "    subplot_col = i%ROWS\n",
        "    ax = axes[subplot_row, subplot_col]\n",
        "\n",
        "    plottable_image = np.reshape(sample_images[i,:], (28,28))\n",
        "    ax.imshow(plottable_image, cmap='gray_r')\n",
        "    \n",
        "    ax.set_xbound([0,28])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2JRMCQOq5i7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfed5053-4d13-48e2-df02-8302877e2f2e"
      },
      "source": [
        "# Normalize images to the [0, 1] range\n",
        "# This is to make the calculations more efficient\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class label vectors to binary class matrices (convert to 1-hot format)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAhXPgZuublL"
      },
      "source": [
        "# 2. Select/Design Model\n",
        "\n",
        "Choose one of these models to train. DO NOT RUN ALL CELLS HERE. Just choose one, then see the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWyId3LwNI5"
      },
      "source": [
        "# 2-layer NN\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "      layers.Flatten(input_shape=(28, 28)),   # Input layer\n",
        "      layers.Dense(100, activation='relu'),    # Hidden layer(s)\n",
        "      layers.Dense(num_classes, activation='softmax')  # Output layer\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "5OOcxMHIsB3f",
        "outputId": "75e2742a-589f-4df7-a882-404b9467d161"
      },
      "source": [
        "# CNN LeNet model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "      keras.Input(shape=input_shape)\n",
        "      layers.Conv2D(32, kernel_size=(3, 3), activation='relu'), #C1\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)), #S2\n",
        "      layers.Conv2D(32, kernel_size=(3, 3), activation='relu'), #C3\n",
        "      layers.MaxPooling2D(pool_size=(2, 2)), #S4\n",
        "      layers.Flatten(), #Flatten\n",
        "      layers.Dense(64, activation='relu'), #C5\n",
        "      layers.Dense(num_classes, activation='softmax') #Output layer\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-11a5198e952b>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'), #C1\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0cuVgLTQqp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0729ada8-0d7a-4a99-a2bf-135f64f451d7"
      },
      "source": [
        "# LeNet-5 model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "      layers.Conv2D(10, kernel_size=5, strides=1,  activation='relu', padding='same', input_shape=x_train[0].shape), #C1\n",
        "      layers.AveragePooling2D(), #S2\n",
        "      layers.Conv2D(16, kernel_size=5, strides=1, activation='relu', padding='valid'), #C3\n",
        "      layers.AveragePooling2D(), #S4\n",
        "      layers.Flatten(), #Flatten\n",
        "      layers.Dense(120, activation='relu'), #C5\n",
        "      layers.Dense(84, activation='relu'), #F6\n",
        "      layers.Dense(num_classes, activation='softmax') #Output layer\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 10)        260       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        4016      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 63,410\n",
            "Trainable params: 63,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8JAyLjWvLWH"
      },
      "source": [
        "# 3. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wm7qx7gP72Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfaf329f-2166-484f-bc83-547ac820c108"
      },
      "source": [
        "# set the loss, optimizer and metrics\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
        "\n",
        "# train/fit the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 3s 5ms/step - loss: 0.0479 - accuracy: 0.9864 - val_loss: 0.0534 - val_accuracy: 0.9867\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 0.0530 - val_accuracy: 0.9888\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.0595 - val_accuracy: 0.9883\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.0618 - val_accuracy: 0.9872\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 0.0755 - val_accuracy: 0.9858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60f01d00d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-r9YVivP-L3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d23031f-f43f-4cd7-be8d-1517a3e251a4"
      },
      "source": [
        "# Evaluate the trained model performance\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0699 - accuracy: 0.9860\n",
            "Test loss: 0.06985359638929367\n",
            "Test accuracy: 0.9860000014305115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0supgTUEvNV5"
      },
      "source": [
        "# 4. Test the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix_4txM0xWvz"
      },
      "source": [
        "### Make a canvas for user to draw a digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpumNF-fuyV_"
      },
      "source": [
        "# Make a canvas for user to draw a digit\n",
        "# then save the drawing as a png file\n",
        "# source: https://gist.github.com/korakot/8409b3feec20f159d8a50b0a811d3bca\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.fillStyle = \"white\";\n",
        "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(filename='drawing.png', w=150, h=150, line_width=10):\n",
        "  display(HTML(canvas_html % (w, h, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "    print(\"image saved as: \")\n",
        "    print(filename)\n",
        "  # return len(binary)\n",
        "\n",
        "draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "habVaeznymeh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps # import pillow image manipulation tool\n",
        "\n",
        "# Load the image to be tested\n",
        "user_image = Image.open('drawing.png')\n",
        "user_image = ImageOps.grayscale(user_image)\n",
        "user_image = ImageOps.invert(user_image)\n",
        "\n",
        "# Resize to input_shape\n",
        "user_image = user_image.resize((input_shape[0],input_shape[1]))\n",
        "plt.imshow(user_image)\n",
        "user_image = np.array(user_image).astype(\"float32\") / 255\n",
        "# user_image = np.expand_dims(user_image, axis=0)\n",
        "user_image = user_image.reshape(-1, 28, 28, 1)\n",
        "# print(\"user_image shape:\", user_image.shape)\n",
        "\n",
        "# Predict the class of the drawing \n",
        "result = model.predict(user_image)\n",
        "print(result)\n",
        "result = np.argmax(result,axis=1)\n",
        "print(\"The AI thinks this is the number:\", result[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}